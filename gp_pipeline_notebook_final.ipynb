{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08830f0e",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression with Uncertainty Quantification\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete pipeline for Gaussian Process Regression with:\n",
    "- **QuantileTransformer** for input features (X)\n",
    "- **LogTransformer** for target variable (y)\n",
    "- **Hyperparameter optimization** using CV set\n",
    "- **Uncertainty quantification** with standard deviations\n",
    "- **Comprehensive visualization** of predictions and uncertainty\n",
    "\n",
    "## Key Features\n",
    "1. Scikit-learn pipeline architecture\n",
    "2. Multiple kernel options tested\n",
    "3. Proper handling of std predictions\n",
    "4. Visualization of first 50 predictions with uncertainty bounds\n",
    "5. Model persistence for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1d4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF, Matern, WhiteKernel, ConstantKernel as C, RationalQuadratic\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "import joblib\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385582c9",
   "metadata": {},
   "source": [
    "## 1. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "  random_state: 42\n",
      "  n_quantiles: 100\n",
      "  output_distribution: normal\n",
      "  n_restarts_optimizer: 10\n",
      "  alpha: 1e-10\n",
      "  normalize_y: False\n",
      "  plot_samples: 50\n",
      "  save_model: True\n",
      "  model_path: gp_model_optimized.pkl\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'random_state': 42,\n",
    "    'n_quantiles': 100,\n",
    "    'output_distribution': 'normal',\n",
    "    'n_restarts_optimizer': 10,\n",
    "    'alpha': 1e-10,\n",
    "    'normalize_y': False,\n",
    "    'plot_samples': 50,\n",
    "    'save_model': True,\n",
    "    'model_path': 'gp_model_optimized.pkl',\n",
    "}\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce406e8",
   "metadata": {},
   "source": [
    "## 2. Custom Transformers and Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3fc93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom transformers defined!\n"
     ]
    }
   ],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Log transformation for target variable.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fitted_ = False\n",
    "    \n",
    "    def fit(self, y, **fit_params):\n",
    "        self.fitted_ = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        if not self.fitted_:\n",
    "            raise RuntimeError(\"Transformer must be fitted before transform\")\n",
    "        return np.log1p(y)\n",
    "    \n",
    "    def inverse_transform(self, y):\n",
    "        return np.expm1(y)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "            return None\n",
    "        return [f\"{name}_log\" for name in input_features]\n",
    "\n",
    "\n",
    "class GPRegressorWithStd(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Wrapper for GaussianProcessRegressor that stores std predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel=None, alpha=1e-10, n_restarts_optimizer=10, \n",
    "                 normalize_y=False, random_state=None):\n",
    "        self.kernel = kernel\n",
    "        self.alpha = alpha\n",
    "        self.n_restarts_optimizer = n_restarts_optimizer\n",
    "        self.normalize_y = normalize_y\n",
    "        self.random_state = random_state\n",
    "        self.gp_ = None\n",
    "        self.y_std_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.gp_ = GaussianProcessRegressor(\n",
    "            kernel=self.kernel,\n",
    "            alpha=self.alpha,\n",
    "            n_restarts_optimizer=self.n_restarts_optimizer,\n",
    "            normalize_y=self.normalize_y,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        self.gp_.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, return_std=False):\n",
    "        if return_std:\n",
    "            y_pred, y_std = self.gp_.predict(X, return_std=True)\n",
    "            self.y_std_ = y_std\n",
    "            return y_pred\n",
    "        else:\n",
    "            return self.gp_.predict(X, return_std=False)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'kernel': self.kernel,\n",
    "            'alpha': self.alpha,\n",
    "            'n_restarts_optimizer': self.n_restarts_optimizer,\n",
    "            'normalize_y': self.normalize_y,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return r2_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(\"Custom transformers defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a4f0d",
   "metadata": {},
   "source": [
    "## 3. Kernel Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_options():\n",
    "    \"\"\"Define various kernel options for testing.\"\"\"\n",
    "    \n",
    "    # Common bounds (reuse variables for cleaner code)\n",
    "    ls_bounds = (1e-2, 1e2)\n",
    "    c_bounds = (1e-3, 1e3)\n",
    "    noise_bounds = (1e-10, 1e0)\n",
    "    \n",
    "    kernels = {\n",
    "        # --- Standard Kernels ---\n",
    "        # 'matern_1.5': C(1.0, c_bounds) * Matern(\n",
    "        #     length_scale=1.0, length_scale_bounds=ls_bounds, nu=1.5\n",
    "        # ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "        \n",
    "        # 'matern_2.5': C(1.0, c_bounds) * Matern(\n",
    "        #     length_scale=1.0, length_scale_bounds=ls_bounds, nu=2.5\n",
    "        # ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "        \n",
    "        # 'rbf': C(1.0, c_bounds) * RBF(\n",
    "        #     length_scale=1.0, length_scale_bounds=ls_bounds\n",
    "        # ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "        \n",
    "        # 'rational_quadratic': C(1.0, c_bounds) * RationalQuadratic(\n",
    "        #     length_scale=1.0, alpha=1.0,\n",
    "        #     length_scale_bounds=ls_bounds, alpha_bounds=ls_bounds\n",
    "        # ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "        \n",
    "        # --- COMBINED KERNELS (NEW) ---\n",
    "        \n",
    "        # Option 1: Additive (Best for Structural Mechanics)\n",
    "        # RBF captures global smooth trends, Matern captures local interactions\n",
    "        'rbf_plus_matern': (\n",
    "            C(1.0, c_bounds) * RBF(length_scale=1.0, length_scale_bounds=ls_bounds) + \n",
    "            C(1.0, c_bounds) * Matern(length_scale=1.0, length_scale_bounds=ls_bounds, nu=2.5)\n",
    "        ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "        \n",
    "        # Option 2: Multiplicative\n",
    "        # Creates a complex correlation structure\n",
    "        'rbf_times_matern': (\n",
    "            C(1.0, c_bounds) * \n",
    "            RBF(length_scale=1.0, length_scale_bounds=ls_bounds) * \n",
    "            Matern(length_scale=1.0, length_scale_bounds=ls_bounds, nu=2.5)\n",
    "        ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=noise_bounds),\n",
    "    }\n",
    "    return kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 5 kernel options:\n",
      "  - matern_1.5\n",
      "  - matern_2.5\n",
      "  - rbf\n",
      "  - rational_quadratic\n",
      "  - rbf_simple\n"
     ]
    }
   ],
   "source": [
    "# def get_kernel_options():\n",
    "#     \"\"\"Define various kernel options for testing.\"\"\"\n",
    "#     kernels = {\n",
    "#         'matern_1.5': C(1.0, (1e-3, 1e3)) * Matern(\n",
    "#             length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=1.5\n",
    "#         ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e0)),\n",
    "        \n",
    "#         'matern_2.5': C(1.0, (1e-3, 1e3)) * Matern(\n",
    "#             length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=2.5\n",
    "#         ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e0)),\n",
    "        \n",
    "#         'rbf': C(1.0, (1e-3, 1e3)) * RBF(\n",
    "#             length_scale=1.0, length_scale_bounds=(1e-2, 1e2)\n",
    "#         ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e0)),\n",
    "        \n",
    "#         'rational_quadratic': C(1.0, (1e-3, 1e3)) * RationalQuadratic(\n",
    "#             length_scale=1.0, alpha=1.0,\n",
    "#             length_scale_bounds=(1e-2, 1e2), alpha_bounds=(1e-2, 1e2)\n",
    "#         ) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e0)),\n",
    "        \n",
    "#         'rbf_simple': C(1.0, (1e-3, 1e3)) * RBF(\n",
    "#             length_scale=1.0, length_scale_bounds=(1e-2, 1e2)\n",
    "#         ),\n",
    "#     }\n",
    "#     return kernels\n",
    "\n",
    "# kernels = get_kernel_options()\n",
    "# print(f\"Defined {len(kernels)} kernel options:\")\n",
    "# for name in kernels.keys():\n",
    "#     print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f9aa9",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Volumes/SG_Apple/Sensitivity Analysis/Final Model Fitting/sph.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389c70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.groupby('Strat_cat').sample(frac=0.5,random_state=42)\n",
    "sample_df['Strat_cat'].value_counts()\n",
    "\n",
    "train_set, hold_set = train_test_split(\n",
    "    sample_df, test_size=0.5, shuffle=True, stratify=sample_df['Strat_cat'], random_state=42)\n",
    "cv_set, test_set = train_test_split(\n",
    "    hold_set, test_size=0.5, shuffle=True, stratify=hold_set['Strat_cat'], random_state=42)\n",
    "\n",
    "for col in (train_set,cv_set,test_set):\n",
    "    col.drop(['Strat_cat'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded:\n",
      "  Train: X=(2500, 10), y=(2500,)\n",
      "  CV:    X=(1250, 10), y=(1250,)\n",
      "  Test:  X=(1250, 10), y=(1250,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_set.iloc[:, :10].values\n",
    "y_train = train_set.iloc[:, 10].values\n",
    "X_test = test_set.iloc[:, :10].values\n",
    "y_test = test_set.iloc[:, 10].values\n",
    "X_cv = cv_set.iloc[:, :10].values\n",
    "y_cv = cv_set.iloc[:, 10].values\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  CV:    X={X_cv.shape}, y={y_cv.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, y={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e0ce7",
   "metadata": {},
   "source": [
    "## 5. Transform Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d2ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and fit log transformer for target\n",
    "# qt_y = LogTransformer()\n",
    "\n",
    "# y_train_scaled = qt_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "# y_cv_scaled = qt_y.transform(y_cv.reshape(-1, 1)).flatten()\n",
    "# y_test_scaled = qt_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# print(\"Target variable transformed (log1p):\")\n",
    "# print(f\"  Original range: [{y_train.min():.2f}, {y_train.max():.2f}]\")\n",
    "# print(f\"  Scaled range:   [{y_train_scaled.min():.2f}, {y_train_scaled.max():.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4251b8c3",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test different kernels on the CV set to find the best configuration.\n",
    "\n",
    "\n",
    "# def create_pipeline(kernel, config=CONFIG):\n",
    "#     \"\"\"Create pipeline with given kernel.\"\"\"\n",
    "#     return Pipeline([\n",
    "#         ('quantile_transform', QuantileTransformer(\n",
    "#             n_quantiles=config['n_quantiles'],\n",
    "#             output_distribution=config['output_distribution'],\n",
    "#             random_state=config['random_state']\n",
    "#         )),\n",
    "#         ('gp_regressor', GPRegressorWithStd(\n",
    "#             kernel=kernel,\n",
    "#             alpha=config['alpha'],\n",
    "#             n_restarts_optimizer=config['n_restarts_optimizer'],\n",
    "#             normalize_y=config['normalize_y'],\n",
    "#             random_state=config['random_state']\n",
    "#         ))\n",
    "#     ])\n",
    "\n",
    "\n",
    "# # Test each kernel\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"TESTING DIFFERENT KERNELS\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# results = {}\n",
    "# kernels = get_kernel_options()\n",
    "\n",
    "# for kernel_name, kernel in kernels.items():\n",
    "#     print(f\"\\nTesting: {kernel_name}\")\n",
    "#     print(\"-\" * 50)\n",
    "    \n",
    "#     try:\n",
    "#         # Create and fit pipeline\n",
    "#         pipeline = create_pipeline(kernel)\n",
    "#         pipeline.fit(X_train, y_train_scaled)\n",
    "        \n",
    "#         # Predict on CV set\n",
    "#         y_cv_pred = pipeline.predict(X_cv)\n",
    "        \n",
    "#         # Compute metrics\n",
    "#         mse = np.mean((y_cv_scaled - y_cv_pred) ** 2)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mae = np.mean(np.abs(y_cv_scaled - y_cv_pred))\n",
    "#         r2 = r2_score(y_cv_scaled, y_cv_pred)\n",
    "        \n",
    "#         results[kernel_name] = {\n",
    "#             'pipeline': pipeline,\n",
    "#             'mse': mse,\n",
    "#             'rmse': rmse,\n",
    "#             'mae': mae,\n",
    "#             'r2': r2\n",
    "#         }\n",
    "        \n",
    "#         print(f\"  MSE:  {mse:.6f}\")\n",
    "#         print(f\"  RMSE: {rmse:.6f}\")\n",
    "#         print(f\"  MAE:  {mae:.6f}\")\n",
    "#         print(f\"  R²:   {r2:.6f}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"  ❌ Failed: {str(e)}\")\n",
    "#         results[kernel_name] = None\n",
    "\n",
    "# # Find best kernel\n",
    "# valid_results = {k: v for k, v in results.items() if v is not None}\n",
    "# best_kernel_name = min(valid_results, key=lambda k: valid_results[k]['mse'])\n",
    "# best_pipeline = valid_results[best_kernel_name]['pipeline']\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"BEST KERNEL\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"Kernel: {best_kernel_name}\")\n",
    "# print(f\"CV MSE:  {valid_results[best_kernel_name]['mse']:.6f}\")\n",
    "# print(f\"CV RMSE: {valid_results[best_kernel_name]['rmse']:.6f}\")\n",
    "# print(f\"CV R²:   {valid_results[best_kernel_name]['r2']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f339f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nRetraining best model on combined train+CV set...\")\n",
    "\n",
    "# X_combined = np.vstack([X_train, X_cv])\n",
    "# y_combined = np.concatenate([y_train_scaled, y_cv_scaled])\n",
    "\n",
    "# best_pipeline.fit(X_combined, y_combined)\n",
    "\n",
    "# print(\"✓ Final model trained!\")\n",
    "# print(f\"  Training samples: {len(X_combined)}\")\n",
    "# print(f\"  Features: {X_combined.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743cdba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(y_true, y_pred):\n",
    "#     \"\"\"Compute evaluation metrics.\"\"\"\n",
    "#     return {\n",
    "#         \"R2\": f\"{r2_score(y_true, y_pred):.3f}\",\n",
    "#         \"MAE\": f\"{mean_absolute_error(y_true, y_pred):.3f}\",\n",
    "#         \"RMSE\": f\"{root_mean_squared_error(y_true, y_pred):.3f}\",\n",
    "#     }\n",
    "\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"EVALUATION ON TEST SET\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# # Get predictions with standard deviation\n",
    "# gp_model = best_pipeline.named_steps['gp_regressor']\n",
    "# X_test_transformed = best_pipeline.named_steps['quantile_transform'].transform(X_test)\n",
    "\n",
    "# y_pred_scaled = gp_model.predict(X_test_transformed, return_std=True)\n",
    "# y_std_scaled = gp_model.y_std_\n",
    "\n",
    "# # Metrics in scaled space\n",
    "# metrics_scaled = compute_metrics(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "# print(\"\\nMetrics in Scaled Space (log-transformed):\")\n",
    "# for metric, value in metrics_scaled.items():\n",
    "#     print(f\"  {metric:5s}: {value}\")\n",
    "\n",
    "# # Transform back to original space\n",
    "# y_test_original = qt_y.inverse_transform(y_test_scaled)\n",
    "# y_pred_original = qt_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# # Uncertainty bounds (±2σ)\n",
    "# y_lower_original = qt_y.inverse_transform(y_pred_scaled - 2*y_std_scaled)\n",
    "# y_upper_original = qt_y.inverse_transform(y_pred_scaled + 2*y_std_scaled)\n",
    "\n",
    "# # Metrics in original space\n",
    "# metrics_original = compute_metrics(y_test_original, y_pred_original)\n",
    "\n",
    "# print(\"\\nMetrics in Original Space:\")\n",
    "# for metric, value in metrics_original.items():\n",
    "#     print(f\"  {metric:5s}: {value}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first N samples with uncertainty bounds\n",
    "n_samples = min(CONFIG['plot_samples'], len(y_test))\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Predictions with uncertainty bounds\n",
    "ax1.plot(indices, y_test_original[:n_samples], 'ko-', \n",
    "         label='True Values', markersize=6, linewidth=1.5, alpha=0.7)\n",
    "ax1.plot(indices, y_pred_original[:n_samples], 'bs-', \n",
    "         label='Predictions', markersize=5, linewidth=1.5, alpha=0.7)\n",
    "\n",
    "ax1.fill_between(indices, \n",
    "                 y_lower_original[:n_samples], \n",
    "                 y_upper_original[:n_samples],\n",
    "                 alpha=0.3, color='blue', \n",
    "                 label='95% Confidence Interval (±2σ)')\n",
    "\n",
    "ax1.set_xlabel('Sample Index', fontsize=12)\n",
    "ax1.set_ylabel('Target Value (Omega)', fontsize=12)\n",
    "ax1.set_title(f'Predictions with Uncertainty Bounds (First {n_samples} Samples)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals with uncertainty\n",
    "residuals = y_test_original[:n_samples] - y_pred_original[:n_samples]\n",
    "std_width = y_upper_original[:n_samples] - y_pred_original[:n_samples]\n",
    "\n",
    "ax2.scatter(indices, residuals, c='darkred', s=50, alpha=0.6, \n",
    "            label='Residuals')\n",
    "ax2.fill_between(indices, -std_width, std_width,\n",
    "                 alpha=0.2, color='gray', \n",
    "                 label='±2σ Uncertainty')\n",
    "ax2.axhline(y=0, color='black', linestyle='--', linewidth=1.5)\n",
    "\n",
    "ax2.set_xlabel('Sample Index', fontsize=12)\n",
    "ax2.set_ylabel('Residual (True - Predicted)', fontsize=12)\n",
    "ax2.set_title('Residuals with Uncertainty Bounds', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
